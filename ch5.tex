\documentclass{mybourbaki}
\titre{Programmation dynamique}

\lstset{language=Python, numbers = left}

\begin{document}

\section*{Introduction}
C'est une méthode introduite dans le cadre des algorithmes d'optimisation.

\paragraph{Optimisation}Répond à la problématique de maximisation d'une fonction sous un ensemble de contraintes.

\paragraph{Exemples}En autres :
\begin{itemize}
\item la planification ;
\item satisfaction de contraintes ;
\item mathématiques financières.
\end{itemize}

Il y a deux grandes familles de méthodes en optimisation :
\begin{itemize}
\item la programmation dynamique ;
\item la programmation linéaire.
\end{itemize}

\section{Calculer une suite définie par une récurrence sur deux indices}

Soit $f:\N^{3}\vers \N$. On suppose que l'on dispose d'un algorithme $F$ pour calculer $f$.
On s'intéresse à la suite définie par : 
\begin{itemize}
\item $(a_{0,j})_{j\in \N}, (a_{i,0})_{i\in \N}$ donnés ;
\item $a_{i+1,j+1} = f(a_{i,j+1},a_{i+1,j},a_{i,j})$.
\end{itemize}

On vérifie qu'il s'agit bien d'une suite :
\lemme{
Soient $(a_{i,j})_{i,j\in \N}$ et $(b_{i,j})_{i,j\in \N}$ telles que : 
\begin{align*}
a_{i+1,j+1} &= f(a_{i,j+1},a_{i+1,j},a_{i,j}) \\
b_{i+1,j+1}& = f(b_{i,j+1},b_{i+1,j},b_{i,j})
\end{align*}
et : \[ \forall i \in \N, \; a_{i,0} = b_{i,0} \et a_{0,i} = b_{0,i}.\]

Alors $a_{i,j} = b_{i,j}$ pour tout couple $(i,j)\in \N^{2}$.
}{}
\demonstration{ 
Par double récurrence.

On imbrique une récurrence (externe) sur $i$ avec une récurrence (interne) sur $j$.
Sur $i$ on veut montrer : \[ P_i \congru \forall j\in \N, \; a_{i,j} = b_{i,j}.\]
Par définition, $P_0$ est vraie. On suppose $P_i$ vérifiée pour tous $i\leq i_0$. Il s'agit de montrer $P_{i_0+1}$ par récurrence sur $j$.

On définit la proposition : \[ Q_j^{i_0+1} \congru a_{i_0+1,j} = b_{i_0+1,j}.\]
On remarque que $P_{i_0+1}$ est vraie si, et seulement si, $Q_0^{i_0+1},Q_1^{i_0+1},\ldots$ sont vraies. C'est-à-dire que $P_{i_0+1}$ est vraie si, et seulement si : \[ \bigwedge_{j\in \N} Q_j^{i_0+1}.\]
Par définition, $Q_0^{i_0+1}$ est vraie. On suppose $Q_j^{i_0+1}$ vraie pour tous $j\leq j_0$. On a :
\begin{align*}
a_{i_0+1,j_0+1} &= f(a_{i_0,j_0+1},a_{i_0+1,j_0},a_{i_0,j_0}) \\
a_{i_0+1,j_0+1} &= f(b_{i_0,j_{0+1},b_{i_0+1,j_0},b_{i_0,j_0}}\\
a_{i_0+1,j_0+1} &=b_{i_0+1,j_0+1}
\end{align*}
et donc $Q_{j_0+1}^{i_0+1}$ est vraie.

On en conclut que pour tout $i$, $P_i$ est vraie et donc le lemme est démontré.
}{}

Soit $T$ un tableau tel que $T[i,j] = a_{i,j}$.
\paragraph{Algorithme de calcul de $T$}On se donne un algorithme A qui calcule $(a_{i,0})$ et un autre algorithme B qui calcule $(a_{0,i})$.

\begin{lstlisting}
function tabIter(n,m)
	for i from 0 to n do
		T[i,0] = algoA(i)
	for j from 0 to m do
		T[0,j] = algoB(j)
	for i from 1 to n do
		for j from 1 to m do
			T[i,j]=F(T[i-1,j],T[i,j-1],T[i-1,j-1])
	return T				
\end{lstlisting}
\begin{lstlisting}
function tabRec(i,j)
	if i = 0 then
		return algoA(i)
	if j = 0 then
		return algoB(j)
	return F(tabRec(i-1,j),tabRec(i,j-1),tabRec(i-1,j-1))		
\end{lstlisting}

\section{LCS (Least Common Subsequence) : problème d'une plus longue sous-suite commune}

\paragraph{Exemple}Supposons que l'on dispose de deux brins d'ADN : 
\begin{center}
$u$ = t t a t a t g c g t

$v$ = t a t c c c c t t a,
\end{center}
le mot \og t a t t t \fg{} apparait dans les deux brins et est le plus grand.

\subsection{Propriétés}

Soit $\Sigma$ un alphabet fini. 
Soient $u,v\in \Sigma^{*}$. Une sous-suite commune à $u$ et $v$ est un mot $w\in \Sigma^{*}$ tek que : \[ \exists 1\leq i_0 < i_1< \ldots < i_{\abs{w}}, \exists 1 \leq j_0 < j_1 < \ldots < j_{\abs{w}}, \forall k \leq \abs{w}, \; w_{k} = u_{i_k}=v_{j_k}.\]

\paragraph{Notations}On suppose que les mots $w\in \Sigma^{*}$ sont indexés de $1$ à $\abs{w}$. On note également \[ w[1\ldots i] = w[1]w[2]\ldots w[i] = w_1w_2\ldots w_i.\]

Dans la suite on considère le tableau $A : \ens{0,\ldots,n}\fois \ens{0,\ldots,m}$ tel que $A[i,j]$ est la longueur de la plus longue sous-suite commune à $u[1\ldots i]$ et $v[1\ldots j]$.

\proposition{ 
Si $w$ est une sous-suite commune à $u$ et $v$ de longueur maximale $k$, alors pour tout $h\leq k$, $ w[1\ldots h]$ est une sous-suite commune maximale à $u[1\ldots i_h]$ et $v[1\ldots j_h]$.
}{Optimalité des sous-structures}
\demonstration{ 
$w[1\ldots h]$ est bien une sous-suite commune. Si $b$ était une sous-suite, strictement plus grande, à $u[1\ldots i_h]$ et $v[1\ldots j_h]$ alors $bw[h+1,\ldots k]$ serait une sous-suite qui contredirait la maximalité de $w$.
}{}

\paragraph{Notation}$\wedge_{x=y}$ est la fonction constante égale à $1$ si $x=y$ et $0$ sinon.

\proposition{ 
Si $A[0,j]=A[i,0]=0$. Alors \[ A[i+1,j+1] = \max\systeme{&A[i+1,j] \\ &A[i,j+1] \\ &\wedge_{u[i+1]=v[j+1]} + A[i,j] }.\]
}{}
\demonstration{ 
Si une plus longue sous-suite commune à $u[1\ldots i+1]$ et $v[1\ldots j+1]$ à pour dernier élément $u[i+1]=v[j+1]$ alors c'est vérifié. 

Si ce n'est pas le cas, le dernier élément de $w$ est différent, soit de $u[i+1]$ soit de $v[j+1]$
\begin{itemize}
\item dans le premier cas, $w$ est une plus longue sous-suite commune à $u[1\ldots i]$ et $v[i \ldots j+1]$ et c'est donc vérifié ;
\item dans le second cas, $w$ est une plus longue sous-suite commune à $u[1\ldots ui+1]$ et $v[i\ldots j]$ et c'est vérifié.
\end{itemize}
}{}

\subsection{Algorithme}

\begin{lstlisting}
function tabDynLCS(u,v)
	n, m = len(u), len(v)
	for i from 0 to n do A[i,0] = 0
	for j from 0 to m do A[0,j] = 0
	for i from 1 to n do
		for j from 1 to m do
			if A[i-1,j] > A[i,j-1] then
				L[i,j] = nord
				A[i,j] = A[i-1,j]
			else 
				L[i,j] = ouest
				A[i,j] = A[i,j-1]
			if u[i] = v[j] and A[i,j] < 1 + A[i-1,j-1] then
				L[i,j] = nord-ouest
				A[i,j] = 1 + A[i-1,j-1]
	return A,L
function LCS(L,u,v)
	k, i, j = 0, len(n), len(m)
	while min(i,j)) > 0 do
		if L[i,j] = nord-ouest then
			k = k +1
			z[k] = u[i]
			i = i - 1
			j = j - 1 
		else if L[i,j] = ouest then j = j - 1
		else i = i - 1
	return reverse(z)					
\end{lstlisting}

\subsection{Coût}

Le coût de l'algorithme sera le coût des fonctions tabDynLCS et LCS.
\begin{itemize}
\item tabDynLCS demande $\rO(n\times m)$.
\item LCS demande $n+m$ itérations, c'est-à-dire $\rO(n+m)$.
\end{itemize}
Finalement on peut dire que c'est algorithme est en $\rO(n\times m)$ avec $n$ la longueur de la suite $u$ et $m$ celle de $v$.

\section{Problème du sac à dos}

\subsection{Présentation du problème}

Soient des objets numérotés de $1$ à $n$ tel que pour tout $i\leq n$, $w_i$ est le poids de l'objet et $p_i$ sa valeur. La capacité du sac est notée $W$. Le problème étant de maximiser la somme des valeurs des objets mis dans le sac sous la contrainte du poids.

Notons $(x_1,\ldots,x_n)$ une suite de $1$ et $0$ tel que $x_i = 1$ si l'objet $i$ est dans le sac et vaut $0$ sinon. Il s'agit de résoudre le problème \[\systeme{ &\max_{x_i}\sum_{i=1}^{n}x_i p_i \\  &\sum_{i=1}^{n}x_iw_i \leq W }. \]

\subsection{Propriétés}

On définit un tableau $KP[i,c]$, un tableau à deux dimensions avec $0\leq i \leq n$ et $0\leq c\leq W$. $KP[i,c]$ est la valeur optimale d'un sac à dos ne contenant que des objets d'indices inférieurs à $i$ et dont le poids total ne peut dépasser $c$. Plus formellement : \[ KP[i,c] = \max\enstq{\sum_{j\in \cL}p_j}{\cL\dans\ens{1,\ldots,i}\et\sum_{j\in\cL}w_j \leq c}.\] De plus : \[KP[0,c] = KP[i,0] = 0. \]

\proposition{ 
Si $c\geq w_{i+1}$ alors : 
\[ KP[i+1,c] = \max \systeme{  
&KP[i,c] \\
&p_{i+1}+KP[i,c-w_{i+1}]
}.\]
}{}
\demonstration{ 
Si $\cL \dans \ens{1,\ldots,i}\dans\ens{1,\ldots,i,i+1}$ et donc $KP[i,c] \leq KP[i+1,c]$.

Si $\cL \dans\ens{1,\ldots,i+1}$ et $i+1\in\cL$ alors \[\sum_{j\in \cL} p_j = p_{i+1} + \sum_{j\in \cL \prive{i+1}}^{}p_j. \]
On  a \[ KP[i+1,c] \geq p_{i+1} + KP[i,c].\]Et donc \[ KP[i+1,c] \geq \max\ens{KP[i,c],p_{i+1}+KP[i,c-w_{i+1}]}.\]

Supposons qu'il existe une solution $\cL$ au problème $(i+1,c)$.
\begin{itemize}
\item Si $i+1\in \cL$ alors $KP[i+1,c] = p_{i+1} + \sum_{j\in \cL\prive{i+1}}^{}p_j$. Or \[ \sum_{j\in\cL}w_{j} \leq c \ssi \sum_{j\in\cL\prive{i+1}}w_j\leq c-w_{i+1}. \]

$\cL\prive{i+1}$ est nécessairement optimale pour $(i,c-w_{i+1})$. Dans le cas contraire $\cL'\union\ens{i+1}$ nierait l'optimalité de $\cL$. En conclusion, on a \[ KP[i+1,c] = p_{i+1}+KP[i,c-w_{i+1}].\]
\item Si $i+1\not\in\cL$ alors $\cL\dans\ens{1,\ldots,i}$ et donc \[ KP[i+1,c] = KP[i,c].\]
\end{itemize}

On a bien \[ KP[i+1,c] = KP[i,c]\bigwedge_{i+1\not\in \cL} + \left(p_{i+1}+KP[i,c-w_{i+1}]\right)\bigwedge_{i+1\in \cL} = \max\ens{KP[i,c],p_{i+1}+KP[i,c-w_{i+1}]} .\]
}{}

\subsection{L'algorithme}

\begin{lstlisting}
function knapSack(w,n,p,W)
	for i from 0 to n do
		kp[i,0] = 0
	for c from 0 to W do
		kp[0,c] = 0
	for i from 1 to n do
		for c from 1 to W do
			if c > w[i] then
				kp[i,c] = max(kp[i-1,c],p[i] + kp[i-1,c-w[i]])
			else
				kp[i,c] = kp[i-1,c]
	for i from 1 to n do
		x[i] = 0
	c = W
	for i from n to 1 do
		if kp[i,c] != kp[i-1,c] then
			x[i] = 1
			c = c-w[i]				
	return x,kp						
\end{lstlisting}

\end{document}




























